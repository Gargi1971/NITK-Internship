{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHamhFHceFn5bdFEeBiOcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gargi1971/NITK-Internship/blob/main/ResNet18_for_OrganMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWSsejrucjNU",
        "outputId": "4b69d7ed-4d09-45b4-ef38-226973300c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist\n",
        "import medmnist\n",
        "\n",
        "from medmnist import OrganMNIST3D"
      ],
      "metadata": {
        "id": "YyTbOlZrqji-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/MedMNIST\n",
        "\n",
        "train_dataset = medmnist.OrganMNIST3D(root='./', download=True, split= 'train' )\n",
        "test_dataset = medmnist.OrganMNIST3D(root='./', download=True, split= 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQxCh3BPo3Iw",
        "outputId": "d62a8051-a71b-48b5-8c7b-e0f2b6e46cc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/MedMNIST\n",
            "Using downloaded and verified file: ./organmnist3d.npz\n",
            "Using downloaded and verified file: ./organmnist3d.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset = np.load('/content/drive/My Drive/MedMNIST/organmnist3d.npz')"
      ],
      "metadata": {
        "id": "MyeAVyKXRZl8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.files)\n",
        "print(dataset['train_images'])"
      ],
      "metadata": {
        "id": "YcnwIWhgVCD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_shape = dataset['train_images'].shape\n",
        "print(train_images_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3YR5DASSOX",
        "outputId": "35ad7aeb-19b8-43cc-cd0f-cae37b2a71b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(971, 28, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(\n",
        "            in_planes, planes, kernel_size=(3, 3, 3), stride=stride, padding=(1, 1, 1), bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "\n",
        "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=(3, 3, 3),\n",
        "                               stride=1, padding=(1, 1, 1), bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=(3, 3, 3),\n",
        "                               stride=stride, padding=(1, 1, 1), bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.conv3 = nn.Conv3d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=(3, 3, 3),\n",
        "                               stride=1, padding=(1, 1, 1), bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(in_channels, num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "FbF4TNqX184u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet18(in_channels=1, num_classes=11).to(torch.float64).to(device)\n",
        "\n",
        "model.to(torch.float32)\n",
        "sample_input = torch.randn(1, 28, 28, 28)\n",
        "summary(model, input_size=sample_input.size())\n",
        "\n",
        "for param in model.parameters():\n",
        "    # Print the shape of the weights\n",
        "    print(param.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrW7q8TtVO-P",
        "outputId": "cf203e90-b17f-4244-ecaa-8b73f7f7fa1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1       [-1, 64, 28, 28, 28]           1,728\n",
            "       BatchNorm3d-2       [-1, 64, 28, 28, 28]             128\n",
            "            Conv3d-3       [-1, 64, 28, 28, 28]         110,592\n",
            "       BatchNorm3d-4       [-1, 64, 28, 28, 28]             128\n",
            "            Conv3d-5       [-1, 64, 28, 28, 28]         110,592\n",
            "       BatchNorm3d-6       [-1, 64, 28, 28, 28]             128\n",
            "        BasicBlock-7       [-1, 64, 28, 28, 28]               0\n",
            "            Conv3d-8       [-1, 64, 28, 28, 28]         110,592\n",
            "       BatchNorm3d-9       [-1, 64, 28, 28, 28]             128\n",
            "           Conv3d-10       [-1, 64, 28, 28, 28]         110,592\n",
            "      BatchNorm3d-11       [-1, 64, 28, 28, 28]             128\n",
            "       BasicBlock-12       [-1, 64, 28, 28, 28]               0\n",
            "           Conv3d-13      [-1, 128, 14, 14, 14]         221,184\n",
            "      BatchNorm3d-14      [-1, 128, 14, 14, 14]             256\n",
            "           Conv3d-15      [-1, 128, 14, 14, 14]         442,368\n",
            "      BatchNorm3d-16      [-1, 128, 14, 14, 14]             256\n",
            "           Conv3d-17      [-1, 128, 14, 14, 14]           8,192\n",
            "      BatchNorm3d-18      [-1, 128, 14, 14, 14]             256\n",
            "       BasicBlock-19      [-1, 128, 14, 14, 14]               0\n",
            "           Conv3d-20      [-1, 128, 14, 14, 14]         442,368\n",
            "      BatchNorm3d-21      [-1, 128, 14, 14, 14]             256\n",
            "           Conv3d-22      [-1, 128, 14, 14, 14]         442,368\n",
            "      BatchNorm3d-23      [-1, 128, 14, 14, 14]             256\n",
            "       BasicBlock-24      [-1, 128, 14, 14, 14]               0\n",
            "           Conv3d-25         [-1, 256, 7, 7, 7]         884,736\n",
            "      BatchNorm3d-26         [-1, 256, 7, 7, 7]             512\n",
            "           Conv3d-27         [-1, 256, 7, 7, 7]       1,769,472\n",
            "      BatchNorm3d-28         [-1, 256, 7, 7, 7]             512\n",
            "           Conv3d-29         [-1, 256, 7, 7, 7]          32,768\n",
            "      BatchNorm3d-30         [-1, 256, 7, 7, 7]             512\n",
            "       BasicBlock-31         [-1, 256, 7, 7, 7]               0\n",
            "           Conv3d-32         [-1, 256, 7, 7, 7]       1,769,472\n",
            "      BatchNorm3d-33         [-1, 256, 7, 7, 7]             512\n",
            "           Conv3d-34         [-1, 256, 7, 7, 7]       1,769,472\n",
            "      BatchNorm3d-35         [-1, 256, 7, 7, 7]             512\n",
            "       BasicBlock-36         [-1, 256, 7, 7, 7]               0\n",
            "           Conv3d-37         [-1, 512, 4, 4, 4]       3,538,944\n",
            "      BatchNorm3d-38         [-1, 512, 4, 4, 4]           1,024\n",
            "           Conv3d-39         [-1, 512, 4, 4, 4]       7,077,888\n",
            "      BatchNorm3d-40         [-1, 512, 4, 4, 4]           1,024\n",
            "           Conv3d-41         [-1, 512, 4, 4, 4]         131,072\n",
            "      BatchNorm3d-42         [-1, 512, 4, 4, 4]           1,024\n",
            "       BasicBlock-43         [-1, 512, 4, 4, 4]               0\n",
            "           Conv3d-44         [-1, 512, 4, 4, 4]       7,077,888\n",
            "      BatchNorm3d-45         [-1, 512, 4, 4, 4]           1,024\n",
            "           Conv3d-46         [-1, 512, 4, 4, 4]       7,077,888\n",
            "      BatchNorm3d-47         [-1, 512, 4, 4, 4]           1,024\n",
            "       BasicBlock-48         [-1, 512, 4, 4, 4]               0\n",
            "AdaptiveAvgPool3d-49         [-1, 512, 1, 1, 1]               0\n",
            "           Linear-50                   [-1, 11]           5,643\n",
            "================================================================\n",
            "Total params: 33,145,419\n",
            "Trainable params: 33,145,419\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 171.82\n",
            "Params size (MB): 126.44\n",
            "Estimated Total Size (MB): 298.35\n",
            "----------------------------------------------------------------\n",
            "torch.Size([64, 1, 3, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64, 3, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64, 3, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64, 3, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64, 3, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64, 3, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 128, 3, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 64, 1, 1, 1])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 128, 3, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 128, 3, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([256, 128, 3, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 3, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 128, 1, 1, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 3, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 256, 3, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([512, 256, 3, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 3, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 256, 1, 1, 1])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 3, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512, 3, 3, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet18(in_channels=1, num_classes=11).to(torch.float64).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to train mode\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for i, (inputs, labels) in enumerate (train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device).view(-1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        reg = sum(torch.sum(p**2) for p in model.parameters() if p.requires_grad)\n",
        "        lambda_ = 0.0001\n",
        "        loss = criterion(outputs, labels) + (lambda_ / 2) * reg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    training_accuracy = total_correct / total_samples\n",
        "    print(f\"Training Accuracy: {training_accuracy:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).view(-1)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    val_acc = correct / total\n",
        "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B9m-SIDL6qGm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "e5f4f79a-9d8e-4728-c9b9-e4511258496e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-85d1bf19862f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_register_onnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .boxes import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbox_area\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbox_convert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/_register_onnx_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic_opset11\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopset11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from ._internal.exporter import (  # usort:skip. needs to be last to avoid circular import\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mDiagnosticOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mExportOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_beartype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m from torch.onnx._internal.fx import (\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdecomposition_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mpatcher\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpatcher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mONNXTorchPatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model_with_external_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/patcher.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# safetensors is not an exporter requirement, but needed for some huggingface models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msafetensors\u001b[0m  \u001b[0;31m# type: ignore[import]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msafetensors_torch\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# See PEP 484 & https://github.com/google/jax/issues/7570\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from jax._src.core import (\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mAbstractToken\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractToken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mAbstractValue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m                            \u001b[0mHashableFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashableWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref_lru_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                            partition_list, StrictABCMeta)\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_printer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pretty_printer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mcolorama\u001b[0m  \u001b[0;31m# pytype: disable=import-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mcolorama\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_join\u001b[0;34m(*path_parts)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}