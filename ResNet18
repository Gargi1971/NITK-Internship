{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install medmnist","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:15:02.411558Z","iopub.execute_input":"2024-04-23T04:15:02.411856Z","iopub.status.idle":"2024-04-23T04:15:18.835560Z","shell.execute_reply.started":"2024-04-23T04:15:02.411828Z","shell.execute_reply":"2024-04-23T04:15:18.834557Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting medmnist\n  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.1.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.22.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from medmnist) (4.66.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from medmnist) (9.5.0)\nCollecting fire (from medmnist)\n  Downloading fire-0.6.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m904.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.16.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->medmnist) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->medmnist) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2023.4)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (1.11.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (3.2.1)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2023.12.9)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (21.3)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (0.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (1.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->medmnist) (2.31.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->medmnist) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->medmnist) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->medmnist) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->medmnist) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->medmnist) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->medmnist) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->medmnist) (1.3.0)\nDownloading medmnist-3.0.1-py3-none-any.whl (25 kB)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=3d7c9be34f24f52bf6fe2e20695f5f65d1655392d6bcf2ad0c08b3dc35eb0622\n  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\nSuccessfully built fire\nInstalling collected packages: fire, medmnist\nSuccessfully installed fire-0.6.0 medmnist-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import medmnist\nprint(medmnist.__version__)\n!python -m medmnist available","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:16:03.684105Z","iopub.execute_input":"2024-04-23T04:16:03.685014Z","iopub.status.idle":"2024-04-23T04:16:13.402356Z","shell.execute_reply.started":"2024-04-23T04:16:03.684971Z","shell.execute_reply":"2024-04-23T04:16:13.401177Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"3.0.1\nMedMNIST v3.0.1 @ https://github.com/MedMNIST/MedMNIST/\nAll available datasets:\n\tpathmnist       | PathMNIST       | Size: 28 (default), 64, 128, 224.\n\tchestmnist      | ChestMNIST      | Size: 28 (default), 64, 128, 224.\n\tdermamnist      | DermaMNIST      | Size: 28 (default), 64, 128, 224.\n\toctmnist        | OCTMNIST        | Size: 28 (default), 64, 128, 224.\n\tpneumoniamnist  | PneumoniaMNIST  | Size: 28 (default), 64, 128, 224.\n\tretinamnist     | RetinaMNIST     | Size: 28 (default), 64, 128, 224.\n\tbreastmnist     | BreastMNIST     | Size: 28 (default), 64, 128, 224.\n\tbloodmnist      | BloodMNIST      | Size: 28 (default), 64, 128, 224.\n\ttissuemnist     | TissueMNIST     | Size: 28 (default), 64, 128, 224.\n\torganamnist     | OrganAMNIST     | Size: 28 (default), 64, 128, 224.\n\torgancmnist     | OrganCMNIST     | Size: 28 (default), 64, 128, 224.\n\torgansmnist     | OrganSMNIST     | Size: 28 (default), 64, 128, 224.\n\torganmnist3d    | OrganMNIST3D    | Size: 28 (default), 64.\n\tnodulemnist3d   | NoduleMNIST3D   | Size: 28 (default), 64.\n\tadrenalmnist3d  | AdrenalMNIST3D  | Size: 28 (default), 64.\n\tfracturemnist3d | FractureMNIST3D | Size: 28 (default), 64.\n\tvesselmnist3d   | VesselMNIST3D   | Size: 28 (default), 64.\n\tsynapsemnist3d  | SynapseMNIST3D  | Size: 28 (default), 64.\n","output_type":"stream"}]},{"cell_type":"code","source":"from medmnist import OrganMNIST3D\ntrain_dataset = OrganMNIST3D(download=True, split= 'train')\ntest_dataset = OrganMNIST3D(download=True, split= 'test')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:16:21.383847Z","iopub.execute_input":"2024-04-23T04:16:21.384767Z","iopub.status.idle":"2024-04-23T04:16:27.463993Z","shell.execute_reply.started":"2024-04-23T04:16:21.384727Z","shell.execute_reply":"2024-04-23T04:16:27.462995Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading https://zenodo.org/records/10519652/files/organmnist3d.npz?download=1 to /root/.medmnist/organmnist3d.npz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32657349/32657349 [00:02<00:00, 14935065.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/organmnist3d.npz\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv3d(\n            in_planes, planes, kernel_size=(3, 3, 3), stride=stride, padding=(1, 1, 1), bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n\n        self.conv2 = nn.Conv3d(planes, planes, kernel_size=(3, 3, 3),\n                               stride=1, padding=(1, 1, 1), bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv3d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm3d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv3d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.conv2 = nn.Conv3d(planes, planes, kernel_size=(3, 3, 3),\n                               stride=stride, padding=(1, 1, 1), bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.conv3 = nn.Conv3d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm3d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv3d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm3d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=(3, 3, 3),\n                               stride=1, padding=(1, 1, 1), bias=False)\n        self.bn1 = nn.BatchNorm3d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18(in_channels, num_classes):\n    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:16:40.714040Z","iopub.execute_input":"2024-04-23T04:16:40.714843Z","iopub.status.idle":"2024-04-23T04:16:40.742593Z","shell.execute_reply.started":"2024-04-23T04:16:40.714809Z","shell.execute_reply":"2024-04-23T04:16:40.741514Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import precision_score, recall_score\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ResNet18(in_channels=1, num_classes=11).to(torch.float64).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to train mode\n    running_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    for i, (inputs, labels) in enumerate (train_loader):\n        inputs, labels = inputs.to(device), labels.to(device).view(-1)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        reg = sum(torch.sum(p**2) for p in model.parameters() if p.requires_grad)\n        lambda_ = 0.0001\n        loss = criterion(outputs, labels) + (lambda_ / 2) * reg\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n\n        _, predicted = torch.max(outputs, 1)\n        total_correct += (predicted == labels).sum().item()\n        total_samples += labels.size(0)\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n\n    epoch_loss = running_loss / len(train_dataset)\n    print(f\"Training Loss: {epoch_loss:.4f}\")\n\n    training_accuracy = total_correct / total_samples\n    print(f\"Training Accuracy: {training_accuracy:.4f}\")\n\n    # Validation loop\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n    predicted_labels = []\n    true_labels = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device).view(-1)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            predicted_labels.extend(predicted.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n    val_acc = correct / total\n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n\n    precision = precision_score(true_labels, predicted_labels, average='weighted')\n    recall = recall_score(true_labels, predicted_labels, average='weighted')\n    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:16:47.483830Z","iopub.execute_input":"2024-04-23T04:16:47.484579Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/100], Step [1/31], Loss: 2.8100\nEpoch [1/100], Step [2/31], Loss: 3.6070\nEpoch [1/100], Step [3/31], Loss: 3.2076\nEpoch [1/100], Step [4/31], Loss: 3.1458\nEpoch [1/100], Step [5/31], Loss: 2.2505\nEpoch [1/100], Step [6/31], Loss: 2.2619\nEpoch [1/100], Step [7/31], Loss: 2.1963\nEpoch [1/100], Step [8/31], Loss: 2.9960\nEpoch [1/100], Step [9/31], Loss: 2.1459\nEpoch [1/100], Step [10/31], Loss: 2.1149\nEpoch [1/100], Step [11/31], Loss: 2.6054\nEpoch [1/100], Step [12/31], Loss: 2.0966\nEpoch [1/100], Step [13/31], Loss: 1.9917\nEpoch [1/100], Step [14/31], Loss: 2.2189\nEpoch [1/100], Step [15/31], Loss: 2.1087\nEpoch [1/100], Step [16/31], Loss: 1.9558\nEpoch [1/100], Step [17/31], Loss: 1.9202\nEpoch [1/100], Step [18/31], Loss: 2.0233\nEpoch [1/100], Step [19/31], Loss: 1.9167\nEpoch [1/100], Step [20/31], Loss: 2.1838\nEpoch [1/100], Step [21/31], Loss: 1.5837\nEpoch [1/100], Step [22/31], Loss: 1.9222\nEpoch [1/100], Step [23/31], Loss: 1.7945\nEpoch [1/100], Step [24/31], Loss: 1.9623\nEpoch [1/100], Step [25/31], Loss: 1.5530\nEpoch [1/100], Step [26/31], Loss: 1.7991\nEpoch [1/100], Step [27/31], Loss: 1.8457\nEpoch [1/100], Step [28/31], Loss: 1.6758\nEpoch [1/100], Step [29/31], Loss: 1.7709\nEpoch [1/100], Step [30/31], Loss: 1.7729\nEpoch [1/100], Step [31/31], Loss: 1.3784\nTraining Loss: 2.1721\nTraining Accuracy: 0.3512\nValidation Accuracy: 0.2770\nPrecision: 0.2544, Recall: 0.2770\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/100], Step [1/31], Loss: 1.7218\nEpoch [2/100], Step [2/31], Loss: 1.5675\nEpoch [2/100], Step [3/31], Loss: 1.4012\nEpoch [2/100], Step [4/31], Loss: 1.8041\nEpoch [2/100], Step [5/31], Loss: 1.5233\nEpoch [2/100], Step [6/31], Loss: 1.5590\nEpoch [2/100], Step [7/31], Loss: 1.5105\nEpoch [2/100], Step [8/31], Loss: 1.5775\nEpoch [2/100], Step [9/31], Loss: 1.3386\nEpoch [2/100], Step [10/31], Loss: 1.4058\nEpoch [2/100], Step [11/31], Loss: 1.5686\nEpoch [2/100], Step [12/31], Loss: 1.6748\nEpoch [2/100], Step [13/31], Loss: 1.3712\nEpoch [2/100], Step [14/31], Loss: 1.3157\nEpoch [2/100], Step [15/31], Loss: 1.7295\nEpoch [2/100], Step [16/31], Loss: 2.3807\nEpoch [2/100], Step [17/31], Loss: 1.4317\nEpoch [2/100], Step [18/31], Loss: 1.1741\nEpoch [2/100], Step [19/31], Loss: 1.2451\nEpoch [2/100], Step [20/31], Loss: 1.3562\nEpoch [2/100], Step [21/31], Loss: 1.4888\nEpoch [2/100], Step [22/31], Loss: 1.0929\nEpoch [2/100], Step [23/31], Loss: 1.2704\nEpoch [2/100], Step [24/31], Loss: 1.7535\nEpoch [2/100], Step [25/31], Loss: 1.2580\nEpoch [2/100], Step [26/31], Loss: 1.3873\nEpoch [2/100], Step [27/31], Loss: 1.0418\nEpoch [2/100], Step [28/31], Loss: 0.9863\nEpoch [2/100], Step [29/31], Loss: 1.4464\nEpoch [2/100], Step [30/31], Loss: 1.8911\nEpoch [2/100], Step [31/31], Loss: 2.0046\nTraining Loss: 1.4818\nTraining Accuracy: 0.5901\nEpoch [3/100], Step [1/31], Loss: 1.1610\nEpoch [3/100], Step [2/31], Loss: 1.3946\nEpoch [3/100], Step [3/31], Loss: 1.7509\nEpoch [3/100], Step [4/31], Loss: 1.1912\nEpoch [3/100], Step [5/31], Loss: 1.0887\nEpoch [3/100], Step [6/31], Loss: 1.4631\nEpoch [3/100], Step [7/31], Loss: 1.2377\nEpoch [3/100], Step [8/31], Loss: 1.6140\nEpoch [3/100], Step [9/31], Loss: 1.5330\nEpoch [3/100], Step [10/31], Loss: 1.0306\nEpoch [3/100], Step [11/31], Loss: 1.1568\nEpoch [3/100], Step [12/31], Loss: 1.4832\nEpoch [3/100], Step [13/31], Loss: 1.2068\nEpoch [3/100], Step [14/31], Loss: 1.2485\nEpoch [3/100], Step [15/31], Loss: 0.9199\nEpoch [3/100], Step [16/31], Loss: 1.4783\nEpoch [3/100], Step [17/31], Loss: 1.1277\nEpoch [3/100], Step [18/31], Loss: 1.4374\nEpoch [3/100], Step [19/31], Loss: 0.9898\nEpoch [3/100], Step [20/31], Loss: 1.3305\nEpoch [3/100], Step [21/31], Loss: 0.9626\nEpoch [3/100], Step [22/31], Loss: 1.2415\nEpoch [3/100], Step [23/31], Loss: 1.1681\nEpoch [3/100], Step [24/31], Loss: 0.9585\nEpoch [3/100], Step [25/31], Loss: 0.9103\nEpoch [3/100], Step [26/31], Loss: 1.0526\nEpoch [3/100], Step [27/31], Loss: 1.4253\nEpoch [3/100], Step [28/31], Loss: 0.7283\nEpoch [3/100], Step [29/31], Loss: 0.9082\nEpoch [3/100], Step [30/31], Loss: 1.1814\nEpoch [3/100], Step [31/31], Loss: 0.7763\nTraining Loss: 1.2077\nTraining Accuracy: 0.6890\nValidation Accuracy: 0.6770\nPrecision: 0.6813, Recall: 0.6770\nEpoch [4/100], Step [1/31], Loss: 0.8644\nEpoch [4/100], Step [2/31], Loss: 1.0176\nEpoch [4/100], Step [3/31], Loss: 1.0356\nEpoch [4/100], Step [4/31], Loss: 0.9175\nEpoch [4/100], Step [5/31], Loss: 1.2380\nEpoch [4/100], Step [6/31], Loss: 0.7915\nEpoch [4/100], Step [7/31], Loss: 0.9943\nEpoch [4/100], Step [8/31], Loss: 1.1526\nEpoch [4/100], Step [9/31], Loss: 1.1959\nEpoch [4/100], Step [10/31], Loss: 0.8424\nEpoch [4/100], Step [11/31], Loss: 0.8011\nEpoch [4/100], Step [12/31], Loss: 1.0375\nEpoch [4/100], Step [13/31], Loss: 0.7826\nEpoch [4/100], Step [14/31], Loss: 0.8298\nEpoch [4/100], Step [15/31], Loss: 0.6692\nEpoch [4/100], Step [16/31], Loss: 0.9798\nEpoch [4/100], Step [17/31], Loss: 1.1583\nEpoch [4/100], Step [18/31], Loss: 1.0457\nEpoch [4/100], Step [19/31], Loss: 1.5227\nEpoch [4/100], Step [20/31], Loss: 0.9666\nEpoch [4/100], Step [21/31], Loss: 0.9871\nEpoch [4/100], Step [22/31], Loss: 0.8699\nEpoch [4/100], Step [23/31], Loss: 1.1652\nEpoch [4/100], Step [24/31], Loss: 0.9157\nEpoch [4/100], Step [25/31], Loss: 0.7642\nEpoch [4/100], Step [26/31], Loss: 1.2841\nEpoch [4/100], Step [27/31], Loss: 0.8264\nEpoch [4/100], Step [28/31], Loss: 1.1381\nEpoch [4/100], Step [29/31], Loss: 0.9462\nEpoch [4/100], Step [30/31], Loss: 0.7803\nEpoch [4/100], Step [31/31], Loss: 0.6696\nTraining Loss: 0.9805\nTraining Accuracy: 0.7775\nValidation Accuracy: 0.6754\nPrecision: 0.7601, Recall: 0.6754\nEpoch [5/100], Step [1/31], Loss: 0.9585\nEpoch [5/100], Step [2/31], Loss: 1.0437\nEpoch [5/100], Step [3/31], Loss: 1.1244\nEpoch [5/100], Step [4/31], Loss: 0.6983\nEpoch [5/100], Step [5/31], Loss: 0.6258\n","output_type":"stream"}]}]}